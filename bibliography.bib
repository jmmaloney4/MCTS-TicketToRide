@article{alphago, title={Mastering the game of Go with deep neural networks and tree search}, volume={529}, DOI={10.1038/nature16961}, number={7587}, journal={Nature}, author={Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and Driessche, George Van Den and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and et al.}, year={2016}, pages={484â€“489}}

@InProceedings{mmcts,
author="Auger, David",
editor="Di Chio, Cecilia
and Cagnoni, Stefano
and Cotta, Carlos
and Ebner, Marc
and Ek{\'a}rt, Anik{\'o}
and Esparcia-Alc{\'a}zar, Anna I.
and Merelo, Juan J.
and Neri, Ferrante
and Preuss, Mike
and Richter, Hendrik
and Togelius, Julian
and Yannakakis, Georgios N.",
title="Multiple Tree for Partially Observable Monte-Carlo Tree Search",
booktitle="Applications of Evolutionary Computation",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="53--62",
abstract="We propose an algorithm for computing approximate Nash equilibria of partially observable games using Monte-Carlo tree search based on recent bandit methods. We obtain experimental results for the game of phantom tic-tac-toe, showing that strong strategies can be efficiently computed by our algorithm.",
isbn="978-3-642-20525-5"
}

@InProceedings{mcts_settlers,
author="Szita, Istv{\'a}n
and Chaslot, Guillaume
and Spronck, Pieter",
editor="van den Herik, H. Jaap
and Spronck, Pieter",
title="Monte-Carlo Tree Search in Settlers of Catan",
booktitle="Advances in Computer Games",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="21--32",
abstract="Games are considered important benchmark opportunities for artificial intelligence research. Modern strategic board games can typically be played by three or more people, which makes them suitable test beds for investigating multi-player strategic decision making. Monte-Carlo Tree Search (MCTS) is a recently published family of algorithms that achieved successful results with classical, two-player, perfect-information games such as Go. In this paper we apply MCTS to the multi-player, non-deterministic board game Settlers of Catan. We implemented an agent that is able to play against computer-controlled and human players. We show that MCTS can be adapted successfully to multi-agent environments, and present two approaches of providing the agent with a limited amount of domain knowledge. Our results show that the agent has a considerable playing strength when compared to game implementation with existing heuristics. So, we may conclude that MCTS is a suitable tool for achieving a strong Settlers of Catan player.",
isbn="978-3-642-12993-3"
}

@articlesDBLP{chess_shogi_self_play,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01815},
  archivePrefix = {arXiv},
  eprint    = {1712.01815},
  timestamp = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inbook{mcts_winands,
author = {Winands, Mark},
year = {2015},
month = {01},
pages = {1-6},
title = {Monte-Carlo Tree Search},
doi = {10.1007/978-3-319-08234-9_12-1},
url = {https://dke.maastrichtuniversity.nl/m.winands/documents/Encyclopedia_MCTS.pdf}
}

@inproceedings{mcts_inaugural,
author = {Chaslot, Guillaume and Bakkes, Sander and Szita, Istvan and Spronck, Pieter},
year = {2008},
month = {01},
pages = {},
title = {Monte-Carlo Tree Search: A New Framework for Game AI.},
journal = {Bijdragen}
}

@article{mcts_survey,
author = {Browne, Cameron and Powley, Edward and Whitehouse, Daniel and Lucas, Simon and Cowling, Peter and Rohlfshagen, Philipp and Tavener, Stephen and Perez Liebana, Diego and Samothrakis, Spyridon and Colton, Simon},
year = {2012},
month = {03},
pages = {1-43},
title = {A Survey of Monte Carlo Tree Search Methods},
volume = {4:1},
journal = {IEEE Transactions on Computational Intelligence and AI in Games},
doi = {10.1109/TCIAIG.2012.2186810}
}

@article{bandit_algorithms,
author = {Coquelin, Pierre and Munos, Remi},
year = {2007},
month = {04},
pages = {},
title = {Bandit Algorithms for Tree Search}
}

@paper{rave,
	author = {Tristan Cazenave},
	title = {Generalized Rapid Action Value Estimation},
	conference = {International Joint Conference on Artificial Intelligence},
	year = {2015},
	keywords = {},
	abstract = {Monte Carlo Tree Search (MCTS) is the state of the art algorithm for many games including the game of Go and General Game Playing (GGP). The standard algorithm for MCTS is Upper Confidence bounds applied to Trees (UCT). For games such as Go a big improvement over UCT is the Rapid Action Value Estimation (RAVE) heuristic. We propose to generalize the RAVE heuristic so as to have more accurate estimates near the leaves. We test the resulting algorithm named GRAVE for Atarigo, Knighthrough, Domineering and Go.},

	url = {https://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/view/10774/10768}
}

@paper{belief_sampling,
	author = {Paolo Ciancarini and Gian Piero Favini},
	title = {Monte Carlo Tree Search Techniques in the Game of Kriegspiel},
	conference = {International Joint Conference on Artificial Intelligence},
	year = {2009},
	keywords = {Kriegspiel; imperfect information; Monte Carlo tree search; planning under uncertainty;  search algorithms; heuristic search},
	abstract = {Monte Carlo tree search has brought significant improvements to the level of computer players in games such as Go, but so far it has not been used very extensively in games of strongly imperfect information with a dynamic board and an emphasis on risk management and decision making under uncertainty. In this paper we explore its application to the game of Kriegspiel (invisible chess), providing three Monte Carlo methods of increasing strength for playing the game with little specific knowledge. We compare these Monte Carlo agents to the strongest known minimax-based Kriegspiel player, obtaining significantly better results with a considerably simpler logic and less domain-specific knowledge.},

	url = {https://www.aaai.org/ocs/index.php/IJCAI/IJCAI-09/paper/view/396/693}
}

@inproceedings{large_belief_states,
author = {Parker, Austin and Nau, Dana and Subrahmanian, V.},
year = {2005},
month = {01},
pages = {254-259},
title = {Game-Tree Search with Combinatorially Large Belief States.}
}